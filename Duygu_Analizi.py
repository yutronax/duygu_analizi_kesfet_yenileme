import time
import cv2
from deepface import DeepFace
import threading
import numpy as np


class Duygu:
    """
    Bu sÄ±nÄ±f kameradan gelen gÃ¶rÃ¼ntÃ¼lerde yÃ¼zleri bulup, o yÃ¼zlerdeki duygularÄ± anlamaya Ã§alÄ±ÅŸÄ±yor.
    Sanki bir arkadaÅŸÄ±n yÃ¼zÃ¼ne bakÄ±p "mutlu musun yoksa Ã¼zgÃ¼n mÃ¼?" diye sormasÄ± gibi.
    """
    
    def __init__(self):
        """Her ÅŸeyi hazÄ±rlayÄ±p, sistemi Ã§alÄ±ÅŸmaya hazÄ±r hale getiriyoruz"""
        # Temel ayarlar - kameranÄ±n nereden geldiÄŸi vs.
        self.video_source = 0
        self.exit = False
        self.gec = True
        self.model_yuklendi = False
        
        # Her duyguyu kaÃ§ kez gÃ¶rdÃ¼ÄŸÃ¼mÃ¼zÃ¼ sayacaÄŸÄ±z
        self.emotion = {
            "angry": 0, 
            "disgust": 0, 
            "fear": 0,
            "happy": 0, 
            "sad": 0, 
            "surprise": 0, 
            "neutral": 0
        }
        
        # Ã–nce yÃ¼z tanÄ±ma, sonra kamera, en son analiz baÅŸlatma
        self._load_models()
        self._setup_camera()
        self._start_analysis_thread()
    
    def _load_models(self):
        """Yapay zeka modellerini yÃ¼klÃ¼yoruz - yÃ¼z bulma ve duygu anlama iÃ§in"""
        # YÃ¼z bulmak iÃ§in Ã¶nceden eÄŸitilmiÅŸ bir model kullanÄ±yoruz
        print("ğŸ“¦ YÃ¼z tespit modeli yÃ¼kleniyor...")
        cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        self.face_cascade = cv2.CascadeClassifier(cascade_path)
        
        # DuygularÄ± anlamak iÃ§in DeepFace'in modelini kullanÄ±yoruz
        print("ğŸ“¦ Emotion modeli yÃ¼kleniyor...")
        self.emotion_model = DeepFace.build_model("Emotion")
        print("âœ… Modeller yÃ¼klendi.")
        self.model_yuklendi = True
    
    def _setup_camera(self):
        """KamerayÄ± aÃ§Ä±p, kaliteli gÃ¶rÃ¼ntÃ¼ alabilmesi iÃ§in ayarlÄ±yoruz"""
        self.cap = cv2.VideoCapture(self.video_source)
        
        if not self.cap.isOpened():
            raise RuntimeError("âš ï¸ Kameraya baÄŸlanÄ±lamadÄ±!")
        
        # GÃ¶rÃ¼ntÃ¼ kalitesi iÃ§in Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ ayarlÄ±yoruz
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    def _start_analysis_thread(self):
        """Analizi arka planda sÃ¼rekli Ã§alÄ±ÅŸtÄ±rmak iÃ§in ayrÄ± bir thread baÅŸlatÄ±yoruz"""
        self.thread = threading.Thread(target=self._run, daemon=True)
        self.thread.start()
        print(" Duygu analiz thread'i baÅŸlatÄ±ldÄ±.")
    
    def _detect_faces(self, frame):
        """
        GÃ¶rÃ¼ntÃ¼de yÃ¼z var mÄ± yok mu bakÄ±yoruz. Varsa nerede olduÄŸunu buluyoruz.
        
        Args:
            frame: BakacaÄŸÄ±mÄ±z gÃ¶rÃ¼ntÃ¼
            
        Returns:
            list: BulduÄŸumuz yÃ¼zlerin konumlarÄ± [(x, y, geniÅŸlik, yÃ¼kseklik), ...]
        """
        # Ã–nce gÃ¶rÃ¼ntÃ¼yÃ¼ siyah-beyaz yapÄ±yoruz (yÃ¼z bulma daha kolay)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # YÃ¼zleri buluyoruz
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,      # GÃ¶rÃ¼ntÃ¼yÃ¼ ne kadar kÃ¼Ã§Ã¼ltÃ¼p bÃ¼yÃ¼tÃ¼rsek
            minNeighbors=5,       # Bir yÃ¼z iÃ§in en az kaÃ§ komÅŸu piksel olsun
            minSize=(30, 30)      # En kÃ¼Ã§Ã¼k yÃ¼z boyutu
        )
        
        return faces
    
    def _analyze_emotion_on_face(self, frame, face_coords):
        """
        BulduÄŸumuz yÃ¼ze bakÄ±p "bu kiÅŸi mutlu mu, Ã¼zgÃ¼n mÃ¼?" diye anlamaya Ã§alÄ±ÅŸÄ±yoruz
        
        Args:
            frame: Tam gÃ¶rÃ¼ntÃ¼
            face_coords: YÃ¼zÃ¼n nerede olduÄŸu (x, y, geniÅŸlik, yÃ¼kseklik)
            
        Returns:
            tuple: (hangi_duygu, ne_kadar_emin)
        """
        x, y, w, h = face_coords
        
        # Sadece yÃ¼z kÄ±smÄ±nÄ± kesip alÄ±yoruz
        face_roi = frame[y:y+h, x:x+w]
        
        # YÃ¼z Ã§ok kÃ¼Ã§Ã¼kse analiz edemeyiz
        if face_roi.shape[0] < 48 or face_roi.shape[1] < 48:
            return None, 0
        
        try:
            # DeepFace'e "bu yÃ¼zdeki duygu ne?" diye soruyoruz
            result = DeepFace.analyze(
                face_roi,
                actions=['emotion'],
                enforce_detection=False,  # Zaten yÃ¼zÃ¼ bulduk, tekrar arama
                silent=True
            )
            
            # En gÃ¼Ã§lÃ¼ duyguyu bulup, ne kadar emin olduÄŸunu Ã¶ÄŸreniyoruz
            dominant_emotion = result[0]['dominant_emotion'].lower()
            confidence_score = result[0]['emotion'][dominant_emotion] / 100.0
            
            return dominant_emotion, confidence_score
            
        except Exception as e:
            print(f"Duygu analizi hatasÄ±: {e}")
            return None, 0
    
    def _process_frame(self, frame):
        """
        Bir fotoÄŸrafÄ± alÄ±p tÃ¼m iÅŸlemi yapÄ±yoruz: yÃ¼z bul, duygu anla
        
        Args:
            frame: Ä°nceleyeceÄŸimiz fotoÄŸraf
        """
        # Ã–nce yÃ¼z arayalÄ±m
        faces = self._detect_faces(frame)
        
        if len(faces) == 0:
            print("ğŸ‘» YÃ¼z tespit edilemedi.")
            return
        
        print(f" {len(faces)} yÃ¼z tespit edildi.")
        
        # En bÃ¼yÃ¼k yÃ¼zÃ¼ seÃ§iyoruz (muhtemelen en Ã¶nemlisi o)
        largest_face = max(faces, key=lambda face: face[2] * face[3])
        
        # O yÃ¼zdeki duyguyu anlamaya Ã§alÄ±ÅŸalÄ±m
        emotion, confidence = self._analyze_emotion_on_face(frame, largest_face)
        
        # Sonucu deÄŸerlendirip kaydedelim
        self._evaluate_emotion_result(emotion, confidence)
    
    def _evaluate_emotion_result(self, emotion, confidence):
        """
        BulduÄŸumuz duygu sonucuna "gÃ¼venebilir miyiz?" diye bakÄ±yoruz
        
        Args:
            emotion: BulduÄŸumuz duygu
            confidence: Ne kadar emin olduÄŸumuz (0-1 arasÄ±)
        """
        if not emotion:
            return
        
        confidence_threshold = 0.6  # %60'dan fazla eminse kabul edelim
        
        if confidence > confidence_threshold:
            # Yeterince eminiz - sayacÄ±mÄ±zÄ± artÄ±ralÄ±m
            self.emotion[emotion] += 1
            print(f"ğŸ™‚ AlgÄ±lanan Duygu: {emotion} ({round(confidence * 100, 1)}%)")
        else:
            # Pek emin deÄŸiliz - sadece bilgi verelim
            print(f"ğŸ¤” Belirsiz duygu: {emotion} ({round(confidence * 100, 1)}%)")
    
    def _run(self):
        """
        Ana Ã§alÄ±ÅŸma dÃ¶ngÃ¼sÃ¼ - sÃ¼rekli kameradan gÃ¶rÃ¼ntÃ¼ alÄ±p analiz ediyoruz
        Bu fonksiyon arka planda Ã§alÄ±ÅŸÄ±r durur
